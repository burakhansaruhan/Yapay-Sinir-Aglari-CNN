{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace30bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "matrix_size = 25\n",
    "num_epochs = 30\n",
    "num_classes = 10 # D-E problemleri için"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772609af",
   "metadata": {},
   "source": [
    "## Problemler:\n",
    "Problem A:  Matriste rasgele konumlarda 2 nokta bulunmaktadır. Model bu 2 nokta arasındaki Öklid mesafesini çıktı olarak verecektir.\n",
    "\n",
    "Problem B:  Matriste değişken sayıda (her girişte farklı sayıda olabilir) N adet (3- 10 arası) nokta (rasgele konumlarda) bulunmaktadır. Model bu noktalardan birbirine en yakın olan ikisi arasındaki Öklid mesafesini çıktı olarak verecektir.\n",
    "\n",
    "Problem C:  Matriste değişken sayıda (her girişte farklı sayıda olabilir) N adet (3- 10 arası) nokta (rasgele konumlarda) bulunmaktadır. Model bu noktalardan birbirine en uzak olan ikisi arasındaki Öklid mesafesini çıktı olarak verecektir.\n",
    "\n",
    "Problem D:  Matriste değişken sayıda (her girişte farklı sayıda olabilir) N adet (1- 10 arası) nokta (rasgele konumlarda) bulunmaktadır. Model nokta sayısını çıktı olarak verecektir.\n",
    "\n",
    "Problem E:  Matriste değişken sayıda (her girişte farklı sayıda olabilir) ve değişken büyüklükte N adet (1-10 arası) kare (rasgele konumlarda) bulunmaktadır. Kareler kesişebilir / kesişmeyebilir. Model kare sayısını çıktı olarak verecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1961be",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(problem, split):\n",
    "    data = np.load(f'data/{problem}_{split}.npz')\n",
    "    X = data['X'].astype(np.float32)\n",
    "    y = data['y'].astype(np.float32).reshape(-1,1)\n",
    "    return X, y\n",
    "\n",
    "class DatasetA(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).unsqueeze(1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Veri yükleme yaptığım kısım\n",
    "X_train, y_train = load_data('A', 'train')  # 800 örnek\n",
    "X_test,  y_test  = load_data('A', 'test')   # 200 örnek\n",
    "train_ds = DatasetA(X_train, y_train)\n",
    "test_ds  = DatasetA(X_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599367f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_A(nn.Module):\n",
    "    def __init__(self, f1=16, f2=32, f3=64, hidden=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,  f1, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), # giriş, çıkış, kernel boyutu ve padding\n",
    "            nn.Conv2d(f1, f2, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f2, f3, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )                                                                # f3 tane 3x3 lük blok var\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(f3 * 3 * 3, hidden), nn.ReLU(),           # gizli katman\n",
    "            nn.Linear(hidden, 1)    # çıktı katmanı (1 tane output olacak çünkü regresyon problemi)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        total += criterion(model(xb), yb).item() * xb.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2566a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, train_loader, test_loader, criterion, optimizer, epochs): # değerlendirme kriteri olarak MSE kullandım. optimizer olarak da ADAM kullandım\n",
    "    train_losses, test_losses = [], []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()                   # eğitim modunu açıyoruz\n",
    "        total_train = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()       # her epochtan önce gradyanları sıfırlıyorum\n",
    "            loss = criterion(model(xb), yb) # loss hesaplıyorum\n",
    "            loss.backward()         # gradyanları hesaplıyorum\n",
    "            optimizer.step()        # ağırlıkları güncelliyorum\n",
    "            total_train += loss.item() * xb.size(0)      # loss ları topluyorum\n",
    "        train_losses.append(total_train / len(train_loader.dataset))    # ortalama loss\n",
    "        \n",
    "        model.eval()\n",
    "        total_test = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:  #test set üzerinde değerlendirme yapıyorum gradyan yok\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                total_test += criterion(model(xb), yb).item() * xb.size(0)\n",
    "        test_losses.append(total_test / len(test_loader.dataset))\n",
    "        print(f\"Epoch {epoch:02d} - Train MSE: {train_losses[-1]:.4f}, Test MSE: {test_losses[-1]:.4f}\")\n",
    "    return train_losses, test_losses\n",
    "\n",
    "# default ayarlar\n",
    "default_lr = 1e-3\n",
    "default_bs = 32\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=default_bs, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=default_bs, shuffle=False)\n",
    "\n",
    "model = CNN_A().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=default_lr)\n",
    "\n",
    "train_losses, test_losses = run_training(model, train_loader, test_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# çiz\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs+1), test_losses,  label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('CNN Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {                                # grid search için parametreler. küçük sayılarda olduğu için iyi ama çarpımlar artıkça kötüleşir                   \n",
    "    'lr': [1e-4, 1e-3, 1e-2],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'f1': [16, 32],\n",
    "    'f2': [32, 64],\n",
    "    'hidden': [32, 64]\n",
    "}\n",
    "\n",
    "results = []\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "total = len(grid['lr'])*len(grid['batch_size'])*len(grid['f1'])*len(grid['f2'])*len(grid['hidden']) # lr 3 , batch_size 3, f1 2, f2 2, hidden 2 \n",
    "cnt = 0                                                                                             # 3*3*2*2*2 = 72 farklı kombinasyondan en iyisini seçecez\n",
    "for lr in grid['lr']:\n",
    "    for bs in grid['batch_size']:\n",
    "        for f1 in grid['f1']:\n",
    "            for f2 in grid['f2']:\n",
    "                for hidden in grid['hidden']:\n",
    "                    cnt += 1\n",
    "                    print(f\"Run {cnt}/{total}: lr={lr}, bs={bs}, f1={f1}, f2={f2}, hidden={hidden}\")\n",
    "                    # DataLoader\n",
    "                    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True)    # yeni değerlerle data loaderi ve altta modeli oluşturuyoruz\n",
    "                    test_loader  = DataLoader(test_ds,  batch_size=bs, shuffle=False)\n",
    "                    # model\n",
    "                    net = CNN_A(f1=f1, f2=f2, f3=f2*2, hidden=hidden).to(device)\n",
    "                    opt = optim.Adam(net.parameters(), lr=lr)   # optimizer olarak ADAM\n",
    "                    # kısa eğitim (10 epoch)\n",
    "                    run_training(net, train_loader, test_loader, criterion, opt, epochs=10)\n",
    "                    mse = evaluate(net, test_loader, criterion)     # test set üzerinde MSE hesaplıyoruz\n",
    "                    results.append({'lr':lr,'bs':bs,'f1':f1,'f2':f2,'hidden':hidden,'mse':mse})\n",
    "\n",
    "# en iyi 5 ayar\n",
    "best5 = sorted(results, key=lambda x: x['mse'])[:5]\n",
    "print(\"Top 5 Hiperparametre :\")\n",
    "for r in best5:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best5[0]\n",
    "opt_lr    = best['lr']\n",
    "opt_bs    = best['bs']\n",
    "opt_f1    = best['f1']\n",
    "opt_f2    = best['f2']\n",
    "opt_hidden= best['hidden']\n",
    "print(f\"En başarılı kombinasyon: lr={opt_lr}, batch_size={opt_bs}, f1={opt_f1}, f2={opt_f2}, hidden={opt_hidden}\")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=opt_bs, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=opt_bs, shuffle=False)\n",
    "\n",
    "# model ve optimizasyon\n",
    "model_opt = CNN_A(f1=opt_f1, f2=opt_f2, f3=opt_f2*2, hidden=opt_hidden).to(device)\n",
    "optimizer_opt = optim.Adam(model_opt.parameters(), lr=opt_lr)\n",
    "\n",
    "# eğitim ve kayıpların hesaplanması\n",
    "train_losses_opt, test_losses_opt = run_training(model_opt, train_loader, test_loader, criterion, optimizer_opt, num_epochs)\n",
    "\n",
    "# Sonuçları çiz\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses_opt, label='Train Loss Opt')\n",
    "plt.plot(range(1, num_epochs+1), test_losses_opt,  label='Test Loss Opt')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Optimize  Hiperparametrelerle Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = {'25%': int(0.25*len(train_ds)), '50%': int(0.5*len(train_ds)), '100%': len(train_ds)}\n",
    "test_results = {}\n",
    "for label, n_samples in data_sizes.items():\n",
    "    print(f\"\\n{label} lik veri kümesi ({n_samples} örnek)\")\n",
    "    idx = np.random.permutation(len(train_ds))[:n_samples]\n",
    "    X_sub = X_train[idx]\n",
    "    y_sub = y_train[idx]\n",
    "    sub_ds = DatasetA(X_sub, y_sub)\n",
    "    tl = DataLoader(sub_ds, batch_size=opt_bs, shuffle=True)\n",
    "    net = CNN_A(f1=opt_f1, f2=opt_f2, f3=opt_f2*2, hidden=opt_hidden).to(device)\n",
    "    optm = optim.Adam(net.parameters(), lr=opt_lr)\n",
    "    # Eğit\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        net.train()\n",
    "        for xb, yb in tl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optm.zero_grad()\n",
    "            loss = criterion(net(xb), yb)\n",
    "            loss.backward()\n",
    "            optm.step()\n",
    "    # test\n",
    "    mse_final = evaluate(net, DataLoader(test_ds, batch_size=opt_bs, shuffle=False), criterion)\n",
    "    test_results[label] = mse_final\n",
    "    print(f\"-> Test MSE: {mse_final:.2f}\")\n",
    "# Sonuçları çiz\\ nplt.figure()\n",
    "plt.bar(list(test_results.keys()), list(test_results.values()))\n",
    "plt.xlabel('Eğitim Veri Oranı')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.title('CNN Test MSE vs Eğitim Veri Oranı')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt.eval()\n",
    "preds, true_vals = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in DataLoader(test_ds, batch_size=opt_bs, shuffle=False):\n",
    "        xb = xb.to(device)\n",
    "        out = model_opt(xb).cpu().numpy().reshape(-1)\n",
    "        preds.extend(out)           # tahminleri listeye ekleme\n",
    "        true_vals.extend(yb.numpy().reshape(-1)) # gerçek değerleri listeye ekleme\n",
    "preds = np.array(preds)\n",
    "true_vals = np.array(true_vals)\n",
    "errors = np.abs(preds - true_vals)\n",
    "\n",
    "# en iyi ve en kötü 5 örnek indeksleri\n",
    "best_idx = np.argsort(errors)[:5]\n",
    "worst_idx = np.argsort(errors)[-5:]\n",
    "\n",
    "#  görselleştirme fonksiyonu\n",
    "def plot_examples(indices, title):\n",
    "    print(title)\n",
    "    fig, axs = plt.subplots(1, len(indices), figsize=(15,3))\n",
    "    for ax, idx in zip(axs, indices):\n",
    "        mat = X_test[idx]\n",
    "        ax.imshow(mat, cmap='gray_r', interpolation='nearest')\n",
    "        # Izgarayı ekle\n",
    "        ax.set_xticks(np.arange(-0.5, matrix_size, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-0.5, matrix_size, 1), minor=True)\n",
    "        ax.grid(which='minor', color='black', linestyle='-', linewidth=0.5)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f\"True: {true_vals[idx]:.2f}\\nPred: {preds[idx]:.2f}\\nErr: {errors[idx]:.2f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_examples(best_idx, \"En İyi Tahminler (Düşük Error)\")\n",
    "plot_examples(worst_idx, \"En Kötü Tahminler (Yüksek Error)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58538e38",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(problem, split):\n",
    "    data = np.load(f'data/{problem}_{split}.npz')\n",
    "    X = data['X'].astype(np.float32) \n",
    "    y = data['y'].astype(np.float32).reshape(-1,1)\n",
    "    return X, y\n",
    "\n",
    "class DatasetB(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).unsqueeze(1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, y_train = load_data('B', 'train')  # 800 örnek\n",
    "X_test,  y_test  = load_data('B', 'test')   # 200 örnek\n",
    "train_ds = DatasetB(X_train, y_train)\n",
    "test_ds  = DatasetB(X_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23663c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_B(nn.Module):\n",
    "    def __init__(self, f1=16, f2=32, f3=64, hidden=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,  f1, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f1, f2, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f2, f3, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(f3 * 3 * 3, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        total += criterion(model(xb), yb).item() * xb.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, train_loader, test_loader, criterion, optimizer, epochs):\n",
    "    train_losses, test_losses = [], []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        t_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t_loss += loss.item() * xb.size(0)\n",
    "        train_losses.append(t_loss / len(train_loader.dataset))\n",
    "        # test\n",
    "        test_losses.append(evaluate(model, test_loader, criterion))\n",
    "        print(f\"Epoch {epoch:02d} - Train MSE: {train_losses[-1]:.4f}, Test MSE: {test_losses[-1]:.4f}\")\n",
    "    return train_losses, test_losses\n",
    "\n",
    "# default ayarlar\n",
    "lr_def = 1e-3\n",
    "bs_def = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=bs_def, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=bs_def, shuffle=False)\n",
    "model_def = CNN_B().to(device)\n",
    "opt_def = optim.Adam(model_def.parameters(), lr=lr_def)\n",
    "\n",
    "train_losses_def, test_losses_def = run_training(model_def, train_loader, test_loader, criterion, opt_def, num_epochs)\n",
    "\n",
    "# Grafik\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses_def, label='Train')\n",
    "plt.plot(range(1, num_epochs+1), test_losses_def,  label='Test')\n",
    "plt.xlabel('Epoch'); plt.ylabel('MSE')\n",
    "plt.title('CNN_B'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'lr': [1e-4,1e-3,1e-2],\n",
    "    'batch_size': [16,32,64],\n",
    "    'f1': [16,32],\n",
    "    'f2': [32,64],\n",
    "    'hidden': [32,64]\n",
    "}\n",
    "results = []\n",
    "cnt = 0\n",
    "total = len(grid['lr'])*len(grid['batch_size'])*len(grid['f1'])*len(grid['f2'])*len(grid['hidden'])\n",
    "for lr in grid['lr']:\n",
    "    for bs in grid['batch_size']:\n",
    "        for f1 in grid['f1']:\n",
    "            for f2 in grid['f2']:\n",
    "                for hid in grid['hidden']:\n",
    "                    cnt += 1\n",
    "                    print(f\"Run {cnt}/{total}: lr={lr}, bs={bs}, f1={f1}, f2={f2}, hidden={hid}\")\n",
    "                    tl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "                    vl = DataLoader(test_ds,  batch_size=bs, shuffle=False)\n",
    "                    net = CNN_B(f1=f1, f2=f2, f3=f2*2, hidden=hid).to(device)\n",
    "                    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "                    run_training(net, tl, vl, criterion, opt, epochs=10)\n",
    "                    mse = evaluate(net, vl, criterion)\n",
    "                    results.append({'lr':lr,'bs':bs,'f1':f1,'f2':f2,'hidden':hid,'mse':mse})\n",
    "# Top5\n",
    "best5 = sorted(results, key=lambda x: x['mse'])[:5]\n",
    "print(\"Top 5 CNN_B parametreleri:\")\n",
    "for r in best5: print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9300ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best5[0]\n",
    "lr_opt = best['lr']; bs_opt = best['bs']\n",
    "f1_opt = best['f1']; f2_opt = best['f2']; hid_opt = best['hidden']\n",
    "print(f\"En başarılı kombinasyon: lr={lr_opt}, bs={bs_opt}, f1={f1_opt}, f2={f2_opt}, hidden={hid_opt}\")\n",
    "train_loader = DataLoader(train_ds, batch_size=bs_opt, shuffle=True)\n",
    "# test loader remains\n",
    "test_loader = DataLoader(test_ds,  batch_size=bs_opt, shuffle=False)\n",
    "model_opt = CNN_B(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "opt_opt = optim.Adam(model_opt.parameters(), lr=lr_opt)\n",
    "train_losses_opt, test_losses_opt = run_training(model_opt, train_loader, test_loader, criterion, opt_opt, num_epochs)\n",
    "# Grafik\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses_opt, label='Train Opt')\n",
    "plt.plot(range(1, num_epochs+1), test_losses_opt,  label='Test Opt')\n",
    "plt.xlabel('Epoch'); plt.ylabel('MSE')\n",
    "plt.title('Optimize  Hiperparametrelerle Loss'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = {'25%':int(0.25*len(train_ds)),'50%':int(0.5*len(train_ds)),'100%':len(train_ds)}\n",
    "res = {}\n",
    "for label,n in data_sizes.items():\n",
    "    print(f\"{label} lik veri kümesi({n} örnek)\")\n",
    "    idx = np.random.permutation(len(train_ds))[:n]\n",
    "    X_sub = X_train[idx]; y_sub = y_train[idx]\n",
    "    sub_ds = DatasetB(X_sub,y_sub)\n",
    "    tl = DataLoader(sub_ds, batch_size=bs_opt, shuffle=True)\n",
    "    net= CNN_B(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "    optm= optim.Adam(net.parameters(), lr=lr_opt)\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        net.train()\n",
    "        for xb,yb in tl:\n",
    "            xb,yb=xb.to(device),yb.to(device)\n",
    "            optm.zero_grad(); loss=criterion(net(xb),yb); loss.backward(); optm.step()\n",
    "    res[label] = evaluate(net, DataLoader(test_ds,batch_size=bs_opt), criterion)\n",
    "    print(f\"-> Test MSE: {res[label]:.4f}\")\n",
    "plt.figure(); plt.bar(res.keys(), res.values()); plt.xlabel('Veri Oranı'); plt.ylabel('Test MSE'); plt.title('CNN_B Test MSE vs Veri Oranı'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfff696",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt.eval(); preds, trues = [], []\n",
    "with torch.no_grad():\n",
    "    for xb,yb in DataLoader(test_ds, batch_size=bs_opt):\n",
    "        xb=xb.to(device)\n",
    "        out=model_opt(xb).cpu().numpy().reshape(-1)\n",
    "        preds.extend(out); trues.extend(yb.numpy().reshape(-1))\n",
    "preds=np.array(preds); trues=np.array(trues)\n",
    "errors=np.abs(preds-trues)\n",
    "\n",
    "# Histogram\n",
    "plt.figure(); plt.hist(errors, bins=30); plt.xlabel('Hata'); plt.ylabel('Frekans'); plt.title('Error Histogram'); plt.show()\n",
    "# Hata vs True\n",
    "plt.figure(); plt.scatter(trues, errors, alpha=0.3); plt.xlabel('True'); plt.ylabel('Error'); plt.title('Error vs True'); plt.show()\n",
    "# En iyi/kötü örnekler\n",
    "best_idx=np.argsort(errors)[:5]; worst_idx=np.argsort(errors)[-5:]\n",
    "\n",
    "def plot_examples(indices, title):\n",
    "    print(title)\n",
    "    fig,axs=plt.subplots(1,len(indices),figsize=(15,3))\n",
    "    for ax,idx in zip(axs,indices):\n",
    "        mat=X_test[idx]\n",
    "        ax.imshow(mat,cmap='gray_r',interpolation='nearest')\n",
    "        ax.set_xticks(np.arange(-0.5,matrix_size,1),minor=True)\n",
    "        ax.set_yticks(np.arange(-0.5,matrix_size,1),minor=True)\n",
    "        ax.grid(which='minor',color='black',linestyle='-',linewidth=0.5)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(f\"T:{trues[idx]:.2f}\\nP:{preds[idx]:.2f}\\nE:{errors[idx]:.2f}\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_examples(best_idx, 'En İyi Tahminler')\n",
    "plot_examples(worst_idx, 'En Kötü Tahminler')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92d934",
   "metadata": {},
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(problem, split):\n",
    "    data = np.load(f'data/{problem}_{split}.npz')\n",
    "    X = data['X'].astype(np.float32)\n",
    "    y = data['y'].astype(np.float32).reshape(-1,1)\n",
    "    return X, y\n",
    "\n",
    "class DatasetC(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).unsqueeze(1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, y_train = load_data('C', 'train')  # 800 örnek\n",
    "X_test,  y_test  = load_data('C', 'test')   # 200 örnek\n",
    "train_ds = DatasetC(X_train, y_train)\n",
    "test_ds  = DatasetC(X_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_C(nn.Module):\n",
    "    def __init__(self, f1=16, f2=32, f3=64, hidden=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,  f1, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f1, f2, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f2, f3, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(f3 * 3 * 3, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        total += criterion(model(xb), yb).item() * xb.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86622e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, train_loader, test_loader, criterion, optimizer, epochs):\n",
    "    train_losses, test_losses = [], []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        t_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            t_loss += loss.item() * xb.size(0)\n",
    "        train_losses.append(t_loss / len(train_loader.dataset))\n",
    "        test_losses.append(evaluate(model, test_loader, criterion))\n",
    "        print(f\"Epoch {epoch:02d} - Train MSE: {train_losses[-1]:.4f}, Test MSE: {test_losses[-1]:.4f}\")\n",
    "    return train_losses, test_losses\n",
    "\n",
    "# Default ayarlar\n",
    "lr_def = 1e-3\n",
    "bs_def = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=bs_def, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=bs_def, shuffle=False)\n",
    "model_def = CNN_C().to(device)\n",
    "opt_def = optim.Adam(model_def.parameters(), lr=lr_def)\n",
    "\n",
    "train_losses_def, test_losses_def = run_training(model_def, train_loader, test_loader, criterion, opt_def, num_epochs)\n",
    "\n",
    "# Grafik\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses_def, label='Train')\n",
    "plt.plot(range(1, num_epochs+1), test_losses_def,  label='Test')\n",
    "plt.xlabel('Epoch'); plt.ylabel('MSE')\n",
    "plt.title('CNN_C'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'lr': [1e-4,1e-3,1e-2],\n",
    "    'batch_size': [16,32,64],\n",
    "    'f1': [16,32],\n",
    "    'f2': [32,64],\n",
    "    'hidden': [32,64]\n",
    "}\n",
    "results = []\n",
    "cnt = 0\n",
    "total = len(grid['lr'])*len(grid['batch_size'])*len(grid['f1'])*len(grid['f2'])*len(grid['hidden'])\n",
    "for lr in grid['lr']:\n",
    "    for bs in grid['batch_size']:\n",
    "        for f1 in grid['f1']:\n",
    "            for f2 in grid['f2']:\n",
    "                for hid in grid['hidden']:\n",
    "                    cnt += 1\n",
    "                    print(f\"Run {cnt}/{total}: lr={lr}, bs={bs}, f1={f1}, f2={f2}, hidden={hid}\")\n",
    "                    tl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "                    vl = DataLoader(test_ds,  batch_size=bs, shuffle=False)\n",
    "                    net = CNN_C(f1=f1, f2=f2, f3=f2*2, hidden=hid).to(device)\n",
    "                    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "                    run_training(net, tl, vl, criterion, opt, epochs=10)\n",
    "                    mse = evaluate(net, vl, criterion)\n",
    "                    results.append({'lr':lr,'bs':bs,'f1':f1,'f2':f2,'hidden':hid,'mse':mse})\n",
    "# Top5\n",
    "best5 = sorted(results, key=lambda x: x['mse'])[:5]\n",
    "print(\"Top 5 CNN_C Hiperparametreleri:\")\n",
    "for r in best5: print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best5[0]\n",
    "lr_opt = best['lr']; bs_opt = best['bs']\n",
    "f1_opt = best['f1']; f2_opt = best['f2']; hid_opt = best['hidden']\n",
    "print(f\"En başarılı kombinasyon: lr={lr_opt}, bs={bs_opt}, f1={f1_opt}, f2={f2_opt}, hidden={hid_opt}\")\n",
    "train_loader = DataLoader(train_ds, batch_size=bs_opt, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=bs_opt, shuffle=False)\n",
    "model_opt = CNN_C(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "opt_opt = optim.Adam(model_opt.parameters(), lr=lr_opt)\n",
    "train_losses_opt, test_losses_opt = run_training(model_opt, train_loader, test_loader, criterion, opt_opt, num_epochs)\n",
    "# Grafik\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses_opt, label='Train Opt')\n",
    "plt.plot(range(1, num_epochs+1), test_losses_opt,  label='Test Opt')\n",
    "plt.xlabel('Epoch'); plt.ylabel('MSE')\n",
    "plt.title('Optimize  Hiperparametrelerle Loss'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = {'25%':int(0.25*len(train_ds)),'50%':int(0.5*len(train_ds)),'100%':len(train_ds)}\n",
    "res = {}\n",
    "for label,n in data_sizes.items():\n",
    "    print(f\"{label} lik veri kümesi ({n} örnek)\")\n",
    "    idx = np.random.permutation(len(train_ds))[:n]\n",
    "    X_sub = X_train[idx]; y_sub = y_train[idx]\n",
    "    sub_ds = DatasetC(X_sub,y_sub)\n",
    "    tl = DataLoader(sub_ds, batch_size=bs_opt, shuffle=True)\n",
    "    net= CNN_C(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "    optm= optim.Adam(net.parameters(), lr=lr_opt)\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        net.train()\n",
    "        for xb,yb in tl:\n",
    "            xb,yb=xb.to(device),yb.to(device)\n",
    "            optm.zero_grad(); loss=criterion(net(xb),yb); loss.backward(); optm.step()\n",
    "    res[label] = evaluate(net, DataLoader(test_ds,batch_size=bs_opt), criterion)\n",
    "    print(f\"{label} -> Test MSE: {res[label]:.4f}\")\n",
    "plt.figure(); plt.bar(res.keys(), res.values()); plt.xlabel('Veri Oranı'); plt.ylabel('Test MSE'); plt.title('CNN_C Test MSE vs Veri Oranı'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt.eval(); preds,trues=[],[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb in DataLoader(test_ds,batch_size=bs_opt):\n",
    "        xb=xb.to(device)\n",
    "        out=model_opt(xb).cpu().numpy().reshape(-1)\n",
    "        preds.extend(out); trues.extend(yb.numpy().reshape(-1))\n",
    "preds=np.array(preds); trues=np.array(trues)\n",
    "errors=np.abs(preds-trues)\n",
    "\n",
    "# Histogram\n",
    "plt.figure(); plt.hist(errors, bins=30); plt.xlabel('Hata'); plt.ylabel('Frekans'); plt.title('Error Histogram'); plt.show()\n",
    "# Error vs True\n",
    "plt.figure(); plt.scatter(trues, errors, alpha=0.3); plt.xlabel('True'); plt.ylabel('Error'); plt.title('Error vs True'); plt.show()\n",
    "# En iyi/kötü örnekler\n",
    "best_idx=np.argsort(errors)[:5]; worst_idx=np.argsort(errors)[-5:]\n",
    "\n",
    "def plot_example(mat, true, pred, err, title_prefix=\"\"):\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    # 1) Matrisin kendisini çiz\n",
    "    ax.imshow(mat, cmap='gray_r', interpolation='nearest')\n",
    "    # 2) Hücre sınırları için ızgara\n",
    "    ax.set_xticks(np.arange(-.5, 25, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, 25, 1), minor=True)\n",
    "    ax.grid(which='minor', color='black', linewidth=0.5)\n",
    "    ax.tick_params(which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    # 3) Noktaları üzerine koy (mat==1 olan koordinatlar)\n",
    "    ys, xs = np.where(mat == 1)\n",
    "    ax.scatter(xs, ys, s=100, facecolors='none', edgecolors='red', linewidths=2)\n",
    "    # 4) Başlık\n",
    "    ax.set_title(\n",
    "        f\"{title_prefix}\\nTrue: {true:.2f}  Pred: {pred:.2f}\\nErr: {err:.2f}\",\n",
    "        fontsize=8\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_examples(best_idx, 'Best Predictions')\n",
    "plot_examples(worst_idx, 'Worst Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775ef96",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(problem, split):\n",
    "    data = np.load(f'data/{problem}_{split}.npz')\n",
    "    X = data['X'].astype(np.float32)\n",
    "    y = data['y'].astype(np.int64).reshape(-1) - 1  # sınıflar 0..9\n",
    "    return X, y\n",
    "\n",
    "class DatasetD(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).unsqueeze(1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, y_train = load_data('D', 'train')\n",
    "X_test,  y_test  = load_data('D', 'test')\n",
    "train_ds = DatasetD(X_train, y_train)\n",
    "test_ds  = DatasetD(X_test,  y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_D(nn.Module):\n",
    "    def __init__(self, f1=16, f2=32, f3=64, hidden=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,  f1, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f1, f2, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f2, f3, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(f3 * 3 * 3, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# eğitim ve değerlendirme fonksiyonları - artık değerlendirme kriteri olarak accuracy hesaplayacaz\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train(); total_loss = 0;\n",
    "    correct = 0\n",
    "    for xb,yb in loader:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(); out=model(xb); loss=criterion(out,yb)\n",
    "        loss.backward(); optimizer.step(); total_loss+=loss.item()*xb.size(0)\n",
    "        pred=out.argmax(dim=1); correct+= (pred==yb).sum().item()\n",
    "    return total_loss/len(loader.dataset), correct/len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval(); total_loss=0; correct=0\n",
    "    for xb,yb in loader:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        out=model(xb); total_loss+=criterion(out,yb).item()*xb.size(0)\n",
    "        correct+= (out.argmax(dim=1)==yb).sum().item()\n",
    "    return total_loss/len(loader.dataset), correct/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f61aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default ayarlar\n",
    "lr_def=1e-3; bs_def=32\n",
    "\n",
    "train_loader=DataLoader(train_ds, batch_size=bs_def, shuffle=True)\n",
    "test_loader=DataLoader(test_ds,  batch_size=bs_def, shuffle=False)\n",
    "model_def=CNN_D().to(device)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model_def.parameters(), lr=lr_def)\n",
    "\n",
    "train_losses, train_accs = [], []\n",
    "test_losses, test_accs = [], []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    tr_loss, tr_acc = train_epoch(model_def, train_loader, criterion, optimizer)\n",
    "    te_loss, te_acc = evaluate(model_def, test_loader, criterion)\n",
    "    train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
    "    test_losses.append(te_loss); test_accs.append(te_acc)\n",
    "    print(f\"Epoch {epoch:02d} - Train Acc: {tr_acc:.3f}, Test Acc: {te_acc:.3f}, Train Loss: {tr_loss:.3f}, Test Loss: {te_loss:.3f}\")\n",
    "\n",
    "# Grafik: Accuracy\n",
    "plt.figure(); plt.plot(range(1,num_epochs+1), train_accs, label='Train Acc'); plt.plot(range(1,num_epochs+1), test_accs, label='Test Acc')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('CNN_D'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={ 'lr':[1e-4,1e-3,1e-2], 'batch_size':[16,32,64], 'f1':[16,32], 'f2':[32,64], 'hidden':[32,64] }\n",
    "results=[]; cnt=0; total=len(grid['lr'])*len(grid['batch_size'])*len(grid['f1'])*len(grid['f2'])*len(grid['hidden'])\n",
    "for lr in grid['lr']:\n",
    "    for bs in grid['batch_size']:\n",
    "        for f1 in grid['f1']:\n",
    "            for f2 in grid['f2']:\n",
    "                for hid in grid['hidden']:\n",
    "                    cnt+=1; print(f\"Run {cnt}/{total}: lr={lr}, bs={bs}, f1={f1}, f2={f2}, hid={hid}\")\n",
    "                    tl=DataLoader(train_ds,batch_size=bs,shuffle=True)\n",
    "                    vl=DataLoader(test_ds,batch_size=bs,shuffle=False)\n",
    "                    net=CNN_D(f1=f1,f2=f2,f3=f2*2,hidden=hid).to(device)\n",
    "                    opt=optim.Adam(net.parameters(), lr=lr)\n",
    "                    for _ in range(10): train_epoch(net, tl, criterion, opt)\n",
    "                    _, acc = evaluate(net, vl, criterion)\n",
    "                    results.append({'lr':lr,'bs':bs,'f1':f1,'f2':f2,'hidden':hid,'acc':acc})\n",
    "best5=sorted(results, key=lambda x: -x['acc'])[:5]\n",
    "print(\"Top 5 CNN_D Hiperparametreleri:\")\n",
    "for r in best5: print(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b551449",
   "metadata": {},
   "outputs": [],
   "source": [
    "best=best5[0]\n",
    "lr_opt=best['lr']; bs_opt=best['bs']; f1_opt=best['f1']; f2_opt=best['f2']; hid_opt=best['hidden']\n",
    "print(f\"En iyi kombinasyon: lr={lr_opt}, bs={bs_opt}, f1={f1_opt}, f2={f2_opt}, hidden={hid_opt}\")\n",
    "train_loader=DataLoader(train_ds,batch_size=bs_opt,shuffle=True)\n",
    "test_loader=DataLoader(test_ds,batch_size=bs_opt,shuffle=False)\n",
    "model_opt=CNN_D(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "opt=optim.Adam(model_opt.parameters(), lr=lr_opt)\n",
    "train_accs_opt, test_accs_opt = [], []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    _, tr_acc = train_epoch(model_opt, train_loader, criterion, opt)\n",
    "    _, te_acc = evaluate(model_opt, test_loader, criterion)\n",
    "    train_accs_opt.append(tr_acc); test_accs_opt.append(te_acc)\n",
    "    print(f\"Epoch {epoch:02d} - Train Acc: {tr_acc:.3f}, Test Acc: {te_acc:.3f}\")\n",
    "plt.figure(); plt.plot(range(1,num_epochs+1), train_accs_opt, label='Train Acc Opt'); plt.plot(range(1,num_epochs+1), test_accs_opt, label='Test Acc Opt')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Optimize  Hiperparametrelerle Acc'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ad7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes={'25%':int(0.25*len(train_ds)),'50%':int(0.5*len(train_ds)),'100%':len(train_ds)}\n",
    "acc_res={}\n",
    "for label,n in data_sizes.items():\n",
    "    print(f\"{label} lik veri kümesi ({n} örnek)\")\n",
    "    idx=np.random.permutation(len(train_ds))[:n]\n",
    "    X_sub=X_train[idx]; y_sub=y_train[idx]\n",
    "    sub_ds=DatasetD(X_sub,y_sub)\n",
    "    tl=DataLoader(sub_ds,batch_size=bs_opt,shuffle=True)\n",
    "    net=CNN_D(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "    optm=optim.Adam(net.parameters(), lr=lr_opt)\n",
    "    for _ in range(num_epochs): train_epoch(net, tl, criterion, optm)\n",
    "    _, acc_res[label] = evaluate(net, DataLoader(test_ds,batch_size=bs_opt), criterion)\n",
    "    print(f\"-> Test Acc: {acc_res[label]:.3f}\")\n",
    "plt.figure(); plt.bar(acc_res.keys(), acc_res.values()); plt.xlabel('Veri Oranı'); plt.ylabel('Test Acc'); plt.title('CNN_D Test Acc vs Veri Oranı'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e98367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt.eval()\n",
    "r_preds, r_trues = [], []\n",
    "with torch.no_grad():\n",
    "    for xb,yb in DataLoader(test_ds,batch_size=bs_opt):\n",
    "        xb=xb.to(device)\n",
    "        out=model_opt(xb).cpu().numpy()\n",
    "        preds=np.argmax(out,axis=1)\n",
    "        r_preds.extend(preds); r_trues.extend(yb.numpy())\n",
    "r_preds=np.array(r_preds); r_trues=np.array(r_trues)\n",
    "correct_idx = np.where(r_preds==r_trues)[0][:5]\n",
    "wrong_idx   = np.where(r_preds!=r_trues)[0][:5]\n",
    "\n",
    "def plot_class_examples(indices, title):\n",
    "    print(title)\n",
    "    fig,axs=plt.subplots(1,len(indices),figsize=(15,3))\n",
    "    for ax,idx in zip(axs, indices):\n",
    "        mat = X_test[idx]\n",
    "        ax.imshow(mat, cmap='gray_r', interpolation='nearest')\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(f\"True:{r_trues[idx]+1}\\nPred:{r_preds[idx]+1}\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_class_examples(correct_idx, 'Doğru Sınıflandırılanlar')\n",
    "plot_class_examples(wrong_idx,   'Yanlış Sınıflandırılanlar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644eeec",
   "metadata": {},
   "source": [
    "# E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec113a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(problem, split):\n",
    "    data = np.load(f'data/{problem}_{split}.npz')\n",
    "    X = data['X'].astype(np.float32)\n",
    "    y = data['y'].astype(np.int64).reshape(-1) - 1   # sınıf etiketleri 0..9\n",
    "    return X, y\n",
    "\n",
    "class DatasetE(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).unsqueeze(1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, y_train = load_data('E', 'train')\n",
    "X_test,  y_test  = load_data('E', 'test')\n",
    "train_ds = DatasetE(X_train, y_train)\n",
    "test_ds  = DatasetE(X_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf39b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_E(nn.Module):\n",
    "    def __init__(self, f1=16, f2=32, f3=64, hidden=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,  f1, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f1, f2, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(f2, f3, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(f3 * 3 * 3, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# eğitim ve değerlendirme fonksiyonları\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train(); total_loss=0; correct=0\n",
    "    for xb, yb in loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(); out = model(xb);\n",
    "        loss = criterion(out, yb); loss.backward(); optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        pred = out.argmax(dim=1); correct += (pred==yb).sum().item()\n",
    "    return total_loss/len(loader.dataset), correct/len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval(); total_loss=0; correct=0\n",
    "    for xb, yb in loader:\n",
    "        xb,yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb); total_loss += criterion(out,yb).item()*xb.size(0)\n",
    "        correct += (out.argmax(dim=1)==yb).sum().item()\n",
    "    return total_loss/len(loader.dataset), correct/len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default ayarlar\n",
    "lr_def=1e-3; bs_def=32\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=bs_def, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=bs_def, shuffle=False)\n",
    "model_def = CNN_E().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_def.parameters(), lr=lr_def)\n",
    "\n",
    "train_losses, train_accs = [], []\n",
    "test_losses, test_accs   = [], []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    tr_loss, tr_acc = train_epoch(model_def, train_loader, criterion, optimizer)\n",
    "    te_loss, te_acc = evaluate(model_def, test_loader, criterion)\n",
    "    train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
    "    test_losses.append(te_loss); test_accs.append(te_acc)\n",
    "    print(f\"Epoch {epoch:02d} - Train Acc: {tr_acc:.3f}, Test Acc: {te_acc:.3f}\")\n",
    "# Grafik: Accuracy\n",
    "plt.figure(); plt.plot(train_accs, label='Train'); plt.plot(test_accs, label='Test')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('CNN_E'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'lr': [1e-4,1e-3,1e-2],\n",
    "    'batch_size': [16,32,64],\n",
    "    'f1': [16,32],\n",
    "    'f2': [32,64],\n",
    "    'hidden': [32,64]\n",
    "}\n",
    "results=[]; cnt=0\n",
    "total = len(grid['lr'])*len(grid['batch_size'])*len(grid['f1'])*len(grid['f2'])*len(grid['hidden'])\n",
    "for lr in grid['lr']:\n",
    "    for bs in grid['batch_size']:\n",
    "        for f1 in grid['f1']:\n",
    "            for f2 in grid['f2']:\n",
    "                for hid in grid['hidden']:\n",
    "                    cnt+=1; print(f\"Run {cnt}/{total}\")\n",
    "                    tl = DataLoader(train_ds,batch_size=bs,shuffle=True)\n",
    "                    vl = DataLoader(test_ds, batch_size=bs,shuffle=False)\n",
    "                    net=CNN_E(f1=f1,f2=f2,f3=f2*2,hidden=hid).to(device)\n",
    "                    opt=optim.Adam(net.parameters(), lr=lr)\n",
    "                    for _ in range(10): train_epoch(net, tl, criterion, opt)\n",
    "                    _, acc = evaluate(net, vl, criterion)\n",
    "                    results.append({'lr':lr,'bs':bs,'f1':f1,'f2':f2,'hidden':hid,'acc':acc})\n",
    "best5 = sorted(results, key=lambda x: -x['acc'])[:5]\n",
    "print(\"Top 5 CNN_E hiperparametreleri:\")\n",
    "for r in best5: print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = best5[1]\n",
    "lr_opt, bs_opt = best['lr'], best['bs']\n",
    "f1_opt, f2_opt, hid_opt = best['f1'], best['f2'], best['hidden']\n",
    "print(f\"En iyi kombinasyon: lr={lr_opt}, bs={bs_opt}, f1={f1_opt}, f2={f2_opt}, hidden={hid_opt}\")\n",
    "train_loader = DataLoader(train_ds, batch_size=bs_opt, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=bs_opt, shuffle=False)\n",
    "model_opt = CNN_E(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "optimizer = optim.Adam(model_opt.parameters(), lr=lr_opt)\n",
    "train_accs_opt, test_accs_opt = [], []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    _, tr_acc = train_epoch(model_opt, train_loader, criterion, optimizer)\n",
    "    _, te_acc = evaluate(model_opt, test_loader, criterion)\n",
    "    train_accs_opt.append(tr_acc); test_accs_opt.append(te_acc)\n",
    "    print(f\"Epoch {epoch:02d} - Train Acc: {tr_acc:.3f}, Test Acc: {te_acc:.3f}\")\n",
    "plt.figure(); plt.plot(train_accs_opt, label='Train'); plt.plot(test_accs_opt, label='Test')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Optimize  Hiperparametrelerle Acc'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes={'25%':int(0.25*len(train_ds)),'50%':int(0.5*len(train_ds)),'100%':len(train_ds)}\n",
    "acc_res={}\n",
    "for label,n in data_sizes.items():\n",
    "    idx=np.random.permutation(len(train_ds))[:n]\n",
    "    sub_ds=DatasetE(X_train[idx], y_train[idx])\n",
    "    tl=DataLoader(sub_ds,batch_size=bs_opt,shuffle=True)\n",
    "    net=CNN_E(f1=f1_opt,f2=f2_opt,f3=f2_opt*2,hidden=hid_opt).to(device)\n",
    "    optm=optim.Adam(net.parameters(), lr=lr_opt)\n",
    "    for _ in range(num_epochs): train_epoch(net, tl, criterion, optm)\n",
    "    _, acc_res[label] = evaluate(net, DataLoader(test_ds,batch_size=bs_opt), criterion)\n",
    "    print(f\"{label} -> Test Acc: {acc_res[label]:.3f}\")\n",
    "plt.figure(); plt.bar(acc_res.keys(), acc_res.values()); plt.xlabel('Veri Oranı'); plt.ylabel('Accuracy'); plt.title('CNN_E Test Acc vs Veri Oranı'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f838be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opt.eval(); preds, trues = [], []\n",
    "with torch.no_grad():\n",
    "    for xb,yb in DataLoader(test_ds, batch_size=bs_opt):\n",
    "        xb=xb.to(device)\n",
    "        out=model_opt(xb).cpu().numpy()\n",
    "        p=np.argmax(out,axis=1)\n",
    "        preds.extend(p); trues.extend(yb.numpy())\n",
    "preds, trues = np.array(preds), np.array(trues)\n",
    "correct_idx = np.where(preds==trues)[0][:5]\n",
    "wrong_idx   = np.where(preds!=trues)[0][:5]\n",
    "\n",
    "def plot_examples(indices, title):\n",
    "    print(title)\n",
    "    fig,axs=plt.subplots(1,len(indices),figsize=(15,3))\n",
    "    for ax,idx in zip(axs,indices):\n",
    "        mat=X_test[idx]\n",
    "        ax.imshow(mat,cmap='gray_r',interpolation='nearest')\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(f\"True:{trues[idx]+1}\\nPred:{preds[idx]+1}\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_examples(correct_idx, 'Doğru Sınıflandırılanlar')\n",
    "plot_examples(wrong_idx,   'Yanlış Sınıflandırılanlar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
